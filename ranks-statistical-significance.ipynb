{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, ShuffleSplit\n",
    "import networkx as nx\n",
    "\n",
    "import itertools\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.adjacency_list_to_graph import build_graph\n",
    "from common.calculate_spring_rank import calculate_spring_rank\n",
    "from common.graph_to_matrix import build_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical significance\n",
    "\n",
    "This page shows and explains the process of finding out SpringRank ranks statistical significance, that are extremely important to get really impressive results during genesis generation process (ahem, during the next few months)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. Building graph of transactions\n",
    "2. Inferring $\\beta$\n",
    "3. Inferring $c$\n",
    "4. Cross-validation process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building graph\n",
    "Throughout the process of model calibration we'll use only part of Ethereum graph. It is placed in file named below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\"./part_data\", sep=\" \", names=[\"from\", \"to\", \"value\", \"block\"])\n",
    "transactions_df[\"value\"] = 1\n",
    "transactions_df = transactions_df.sort_values(\"block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, addresses=None):\n",
    "    if addresses:\n",
    "        dataset = dataset[dataset[\"from\"].isin(addresses) & dataset[\"to\"].isin(addresses)]\n",
    "    return dataset.groupby([\"from\", \"to\"])[\"value\"].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ranks(dataset, alpha):\n",
    "    edges = dataset[\"value\"].to_dict()\n",
    "    graph = build_graph(edges)\n",
    "    nodes = list(graph)\n",
    "    A = build_matrix(graph, nodes)\n",
    "    iterations, raw_rank = calculate_spring_rank(A, alpha=alpha)\n",
    "    \n",
    "    rank = pd.DataFrame()\n",
    "    rank[\"address\"] = nodes\n",
    "    rank[\"rank\"] = raw_rank\n",
    "    \n",
    "    return rank.set_index(\"address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring $\\beta$\n",
    "\n",
    "SpringRank generative model includes formulas to find $E_{ij}$ - number of edges between $i$ and $j$ vertices in both directions, and $P_{ij}$ - proportion of edges that are going from vertex $i$ to vertex $j$. These formulas are going below:\n",
    "\n",
    "$$P_{ij} = \\frac{1}{1 + e^{-2\\beta(s_i - s_j)}}, P_{ji} = 1 - P_{ij}$$\n",
    "\n",
    "$$E_{ij} = c \\exp{-\\frac{\\beta}{2}(s_i - s_j - 1)^2}$$\n",
    "\n",
    "Except the calculated ranks, the described model has two parameters - temperature $\\beta$ and density $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find $\\beta$, we'll treat ranks as constant values and apply maximum likelihood procedure described below:\n",
    "\n",
    "$$L(A|s, \\beta) = -\\beta H(s) - M \\log\\sum_{i, j}\\exp -\\frac{\\beta}{2}(s_i - s_j - 1)^2$$\n",
    "\n",
    "There is a really large distance matrix $s_i - s_j$, so we'll do some sort of hack and calculate derivative not with TensorFlow graph mechanism, but by ourselves. Here it goes:\n",
    "\n",
    "$$L'_{\\beta}(A|s, \\beta) \n",
    "= - H(s) + \\frac{M}{2} \\frac{1}{\\sum_{i, j}e^{-\\frac{\\beta}{2}(s_i - s_j - 1)^2}}\\sum_{i, j}e^{-\\frac{\\beta}{2}(s_i - s_j - 1)^2} (s_i - s_j - 1)^2$$\n",
    "\n",
    "As a result, we'll get $\\beta$ parameter that minimizes loss function $L$ in the presence of fixed ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's a little bit hacky way cause of the size of distances matrix s_i - s_j\n",
    "\n",
    "def predict_edges_sum(dataset, ranks, beta, c):\n",
    "    addresses = set([a for a, _ in dataset.index] + [b for _, b in dataset.index])\n",
    "    ranks = ranks.loc[addresses][\"rank\"].tolist()\n",
    "    dataset_shape = len(ranks)\n",
    "    batch_shape = 10000\n",
    "    assert dataset_shape*batch_shape <= 10000000*1000\n",
    "    ranks_tensor = tf.placeholder(tf.float64, shape=[None, ])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(ranks_tensor)\n",
    "    dataset = dataset.batch(batch_shape)\n",
    "    dataset = dataset.map(lambda x: tf.reduce_sum(c*tf.exp(-beta / 2. * (tf.transpose([x]) - ranks_tensor - 1) ** 2)))\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    s.run(iterator.initializer, {ranks_tensor: ranks})\n",
    "    total_sum = 0\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "        count += 1\n",
    "        print(\"{} of {}\".format(count, dataset_shape // batch_shape), end=\"\\r\")\n",
    "        try:\n",
    "            total_sum += s.run(next_element)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    return total_sum / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edges_sum_derivative(dataset, ranks, beta, c):\n",
    "    addresses = set([a for a, _ in dataset.index] + [b for _, b in dataset.index])\n",
    "    ranks = ranks.loc[addresses][\"rank\"].tolist()\n",
    "    dataset_shape = len(ranks)\n",
    "    batch_shape = 10000\n",
    "    assert dataset_shape*batch_shape <= 10000000*1000\n",
    "    ranks_tensor = tf.placeholder(tf.float64, shape=[None, ])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(ranks_tensor)\n",
    "    dataset = dataset.batch(batch_shape)\n",
    "    \n",
    "    def expression(x):\n",
    "        ranks_difference = (tf.transpose([x]) - ranks_tensor - 1) ** 2\n",
    "        return tf.reduce_sum(c * tf.exp(-beta / 2. * ranks_difference) * ranks_difference)\n",
    "        \n",
    "    dataset = dataset.map(expression)\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    s.run(iterator.initializer, {ranks_tensor: ranks})\n",
    "    total_sum = 0\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "        count += 1\n",
    "        print(\"{} of {}\".format(count, dataset_shape // batch_shape), end=\"\\r\")\n",
    "        try:\n",
    "            total_sum += s.run(next_element)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    return total_sum / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy(dataset, ranks):\n",
    "    dataset[\"from_rank\"] = ranks[\"rank\"].loc[[a for a, _ in dataset.index]].tolist()\n",
    "    dataset[\"to_rank\"] = ranks[\"rank\"].loc[[b for _, b in dataset.index]].tolist()\n",
    "    dataset[\"energy\"] = (dataset[\"from_rank\"] - dataset[\"to_rank\"] - 1) ** 2\n",
    "    return (dataset[\"value\"] * dataset[\"energy\"]).sum() / 2\n",
    "\n",
    "def infer_temperature(dataset, ranks):\n",
    "    H = calculate_energy(dataset, ranks)\n",
    "    M = float(dataset[\"value\"].sum())\n",
    "    beta_variable = tf.Variable(3.7268029290713383, name=\"beta\", dtype=tf.float64)\n",
    "    edges_sum_placeholder = tf.placeholder(tf.float64, shape=(None))\n",
    "    edges_sum_derivative_placeholder = tf.placeholder(tf.float64, shape=(None))\n",
    "    \n",
    "    derivative = - H + (M / 2) * (1 / edges_sum_placeholder) * edges_sum_derivative_placeholder\n",
    "    \n",
    "    @tf.custom_gradient\n",
    "    def loss_function(x):\n",
    "        loss = - H * x - M * edges_sum_placeholder\n",
    "        def grad(dy):\n",
    "            return dy * derivative\n",
    "        return loss, grad\n",
    "    \n",
    "    loss = loss_function(beta_variable)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    \n",
    "    s.run(tf.global_variables_initializer())\n",
    "    for i in tqdm_notebook(range(0, 100)):\n",
    "        try:\n",
    "            beta = s.run(beta_variable)\n",
    "            edges_sum = predict_edges_sum(dataset, ranks, beta=beta, c=1)\n",
    "            edges_sum_derivative = calculate_edges_sum_derivative(dataset, ranks, beta=beta, c=1)\n",
    "            variables = {\n",
    "                edges_sum_placeholder: edges_sum, \n",
    "                edges_sum_derivative_placeholder: edges_sum_derivative\n",
    "            }\n",
    "            s.run(optimizer, variables)\n",
    "            print(\"Loss:\", s.run(loss, variables))\n",
    "            print(\"Derivative:\", s.run(derivative, variables))\n",
    "            print(\"Beta:\", s.run(beta_variable))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    return s.run(beta_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infer_temperature(train, ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inferring $c$\n",
    "We'll infer generative model density simply by dividing the sum of predicted edges by the sum of edges that are presented in train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_density(dataset, ranks, beta):\n",
    "    edges_sum = predict_edges_sum(dataset, ranks, beta, 1)\n",
    "    return dataset[\"value\"].sum() / edges_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation\n",
    "Generative model parameters are inferred, so we can try to cross-validate results. High value of metric after cross-validation procedure will be an indicator that we chose $\\alpha, \\beta, c$ parameters properly, and calcucated ranks are statistically significant\n",
    "\n",
    "To start a process, we need to calculate edges number between vertices $E_{ij}$ and their directions $p_{ij}$, and to measure the performance of our model. All calculations we should do over the chunked dataset, each chunk will play a role of test part, the rest of dataset will be the train part. The SpringRank paper describes multigraph accuracy as a measure of model performance, formula goes below:\n",
    "$$\\sigma_a = 1 - \\frac{1}{2M}\\sum_{i,j}|{A_{ij} - (A_{ij} + A_{ji})P_{ij}}|$$\n",
    "Where $M$ - overall number of edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to say that we can deal with multigraph accuracy much faster on sparse graph with skipping empty edges in one and in both directions. We can treat both cases in a way described below:\n",
    "\n",
    "1. If $A_{ij} \\neq 0 $ and $A_{ji} = 0$: $E_{ji}(1 - P_{ji}) + |A_{ji} - E_{ji}P_{ji}|$\n",
    "2. If $A_{ij} = 0$ and $A_{ji} = 0$: $E_{ij}$\n",
    "\n",
    "So the accuracy of predictions for such edges can be described by this formula:\n",
    "$$\\sum E_{ij} - \\frac{\\sum_{(i,j), (j,i) \\in G} E_{ij}}{2} - \\sum_{(i,j) \\in G, (j, i) \\in G} E_{ij}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_edges(dataset, ranks, beta, c):\n",
    "    dataset[\"from_rank\"] = ranks.loc[[a for a, _ in dataset.index]][\"rank\"].tolist()\n",
    "    dataset[\"to_rank\"] = ranks.loc[[b for _, b in dataset.index]][\"rank\"].tolist()\n",
    "    dataset[\"direction_probability\"] = (1 / (1 + np.exp(-2 * beta * (dataset[\"from_rank\"] - dataset[\"to_rank\"]))))\n",
    "    dataset[\"number_of_edges\"] = c * np.exp(- beta / 2 * (dataset[\"from_rank\"] - dataset[\"to_rank\"] - 1) ** 2)\n",
    "    return dataset[\"direction_probability\"].tolist(), dataset[\"number_of_edges\"].tolist(), predict_edges_sum(dataset, ranks, beta, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataset, direction, edges, edges_sum):\n",
    "    accuracy_dataset = dataset.copy()\n",
    "    accuracy_dataset = accuracy_dataset.merge(accuracy_dataset.reset_index(), left_index=True, right_on=[\"to\", \"from\"], how=\"left\", suffixes=('', '_reversed'))\n",
    "    accuracy_dataset[\"not_paired\"] = 0\n",
    "    accuracy_dataset.loc[np.isnan(accuracy_dataset[\"value_reversed\"]), \"not_paired\"] = 1\n",
    "    accuracy_dataset[\"direction\"] = direction\n",
    "    accuracy_dataset[\"edges\"] = edges\n",
    "    accuracy_dataset[\"prediction\"] = accuracy_dataset[\"direction\"] * accuracy_dataset[\"edges\"]\n",
    "    accuracy_dataset[\"error\"] = np.abs(accuracy_dataset[\"value\"] - accuracy_dataset[\"prediction\"])\n",
    "    accuracy_dataset[\"non_paired_error\"] = accuracy_dataset[\"not_paired\"] * accuracy_dataset[\"edges\"] * (1 - accuracy_dataset[\"direction\"])\n",
    "    non_active_edges_sum = edges_sum - (accuracy_dataset[\"not_paired\"] * accuracy_dataset[\"edges\"]).sum() - ((1 - accuracy_dataset[\"not_paired\"]) * accuracy_dataset[\"edges\"]).sum() / 2\n",
    "    return 1 - \\\n",
    "        (accuracy_dataset[\"error\"].sum() + accuracy_dataset[\"non_paired_error\"].sum() + non_active_edges_sum) / \\\n",
    "        (accuracy_dataset[\"value\"].sum() + edges_sum) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df[\"from\"] = [\"0x1\", \"0x2\", \"0x3\"]\n",
    "test_df[\"to\"] = [\"0x2\", \"0x1\", \"0x4\"]\n",
    "test_df[\"value\"] = [1, 2, 1]\n",
    "test_df = test_df.set_index([\"from\", \"to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alphas = [0]\n",
    "# alphas = np.logspace(-2, 2, 5)\n",
    "betas = [4922.40704411323]\n",
    "# betas = [288808]\n",
    "split = ShuffleSplit(n_splits=5)\n",
    "# split = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "train_metrics = {}\n",
    "test_metrics = {}\n",
    "\n",
    "train_index, test_index = next(split.split(transactions_df))\n",
    "# for train_index, test_index in :\n",
    "train = create_dataset(transactions_df.loc[train_index])\n",
    "print(\"Train size: {} samples\".format(train.shape[0]))\n",
    "train_addresses = list([a for a, _ in train.index] + [b for _, b in train.index])\n",
    "test = create_dataset(transactions_df.loc[test_index], addresses=train_addresses)\n",
    "print(\"Test size: {} samples\".format(test.shape[0]))\n",
    "for alpha in alphas:\n",
    "    ranks = find_ranks(train, alpha=alpha)\n",
    "    for beta in betas:\n",
    "        c = infer_density(train, ranks, beta=beta)\n",
    "        train_directions, train_edges, train_sum = predict_edges(train, ranks, beta=beta, c=c)\n",
    "        print(beta * c, train_sum)\n",
    "        test_directions, test_edges, test_sum = predict_edges(test, ranks, beta=beta, c=c)\n",
    "        print(train_sum, test_sum)\n",
    "        train_metrics[(alpha, beta, c)] = train_metrics.get((alpha, beta, c), []) + [accuracy(train, train_directions, train_edges, train_sum)]\n",
    "        test_metrics[(alpha, beta, c)] = test_metrics.get((alpha, beta, c), []) + [accuracy(test, test_directions, test_edges, test_sum)]\n",
    "        print(\"Train accuracy: \", train_metrics[(alpha, beta, c)][-1])\n",
    "        print(\"Test accuracy: \", test_metrics[(alpha, beta, c)][-1])\n",
    "pprint(train_metrics)\n",
    "pprint(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics_df = pd.DataFrame().from_dict(train_metrics).mean().to_frame().reset_index().rename(columns={\"level_0\": \"alpha\", \"level_1\": \"beta\", 0: \"accuracy\", \"level_2\": \"c\"})\n",
    "test_metrics_df = pd.DataFrame().from_dict(test_metrics).mean().to_frame().reset_index().rename(columns={\"level_0\": \"alpha\", \"level_1\": \"beta\", 0: \"accuracy\", \"level_2\": \"c\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_metrics_df[\"alpha_log\"] = np.log(test_metrics_df[\"alpha\"])\n",
    "train_metrics_df[\"alpha_log\"] = np.log(train_metrics_df[\"alpha\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some cross-validation statistics will be plotted there. Now these cells are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_metrics_df.groupby(\"alpha_log\")[\"accuracy\"].mean(), label=\"train\")\n",
    "plt.plot(test_metrics_df.groupby(\"alpha_log\")[\"accuracy\"].mean(), label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_metrics_df.groupby(\"beta\")[\"accuracy\"].max(), label=\"train\")\n",
    "plt.plot(test_metrics_df.groupby(\"beta\")[\"accuracy\"].max(), label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_metrics_df.groupby(\"c\")[\"accuracy\"].max(), label=\"train\")\n",
    "plt.plot(test_metrics_df.groupby(\"c\")[\"accuracy\"].max(), label=\"test\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
