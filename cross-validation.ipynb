{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, ShuffleSplit\n",
    "import networkx as nx\n",
    "\n",
    "import itertools\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common.adjacency_list_to_graph import build_graph\n",
    "from common.calculate_spring_rank import calculate_spring_rank\n",
    "from common.graph_to_matrix import build_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\"./part_data\", sep=\" \", names=[\"from\", \"to\", \"value\", \"block\"])\n",
    "transactions_df[\"value\"] = 1\n",
    "transactions_df = transactions_df.sort_values(\"block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для теста используем граф с выраженной иерархией, например, граф цитат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_df = pd.read_csv(\"Cit-HepPh.txt\", sep=\"\\t\", names=[\"from\", \"to\"])\n",
    "transactions_df[\"value\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, addresses=None):\n",
    "    if addresses:\n",
    "        dataset = dataset[dataset[\"from\"].isin(addresses) & dataset[\"to\"].isin(addresses)]\n",
    "    return dataset.groupby([\"from\", \"to\"])[\"value\"].sum().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ranks(dataset, alpha):\n",
    "    edges = dataset[\"value\"].to_dict()\n",
    "    graph = build_graph(edges)\n",
    "    nodes = list(graph)\n",
    "    A = build_matrix(graph, nodes)\n",
    "    iterations, raw_rank = calculate_spring_rank(A, alpha=alpha)\n",
    "    \n",
    "    rank = pd.DataFrame()\n",
    "    rank[\"address\"] = nodes\n",
    "    rank[\"rank\"] = raw_rank\n",
    "    \n",
    "    return rank.set_index(\"address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель предсказания дуг:\n",
    "$$P_{ij} = \\frac{1}{1 + e^{-2\\beta(s_i - s_j)}}$$\n",
    "$$P_{ji} = \\frac{1}{1 + e^{2\\beta(s_i - s_j)}} $$\n",
    "$$P_{ij} = 1 - P_{ji}$$\n",
    "\n",
    "$$E_{ij} = c \\exp{-\\frac{\\beta}{2}(s_i - s_j - 1)^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict_edges(dataset, ranks, beta):\n",
    "#     dataset[\"from_rank\"] = ranks.loc[[a for a, _ in dataset.index]][\"rank\"].tolist()\n",
    "#     dataset[\"to_rank\"] = ranks.loc[[b for _, b in dataset.index]][\"rank\"].tolist()\n",
    "#     return (1 / (1 + np.exp(-2 * beta * (dataset[\"from_rank\"] - dataset[\"to_rank\"])))).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_edges_sum(dataset, ranks, beta, c):\n",
    "    addresses = set([a for a, _ in dataset.index] + [b for _, b in dataset.index])\n",
    "    ranks = ranks.loc[addresses][\"rank\"].tolist()\n",
    "    dataset_shape = len(ranks)\n",
    "    batch_shape = 10000\n",
    "    assert dataset_shape*batch_shape <= 10000000*1000\n",
    "    ranks_tensor = tf.placeholder(tf.float64, shape=[None, ])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(ranks_tensor)\n",
    "    dataset = dataset.batch(batch_shape)\n",
    "    dataset = dataset.map(lambda x: tf.reduce_sum(c*tf.exp(-beta / 2. * (tf.transpose([x]) - ranks_tensor - 1) ** 2)))\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    s.run(iterator.initializer, {ranks_tensor: ranks})\n",
    "    total_sum = 0\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "        count += 1\n",
    "        print(\"{} of {}\".format(count, dataset_shape // batch_shape), end=\"\\r\")\n",
    "        try:\n",
    "            total_sum += s.run(next_element)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    return total_sum / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_edges_sum_derivative(dataset, ranks, beta, c):\n",
    "    addresses = set([a for a, _ in dataset.index] + [b for _, b in dataset.index])\n",
    "    ranks = ranks.loc[addresses][\"rank\"].tolist()\n",
    "    dataset_shape = len(ranks)\n",
    "    batch_shape = 10000\n",
    "    assert dataset_shape*batch_shape <= 10000000*1000\n",
    "    ranks_tensor = tf.placeholder(tf.float64, shape=[None, ])\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(ranks_tensor)\n",
    "    dataset = dataset.batch(batch_shape)\n",
    "    \n",
    "    def expression(x):\n",
    "        ranks_difference = (tf.transpose([x]) - ranks_tensor - 1) ** 2\n",
    "        return tf.reduce_sum(c * tf.exp(-beta / 2. * ranks_difference) * ranks_difference)\n",
    "        \n",
    "    dataset = dataset.map(expression)\n",
    "\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    next_element = iterator.get_next()\n",
    "\n",
    "    s.run(iterator.initializer, {ranks_tensor: ranks})\n",
    "    total_sum = 0\n",
    "    count = 0\n",
    "    \n",
    "    while True:\n",
    "        count += 1\n",
    "        print(\"{} of {}\".format(count, dataset_shape // batch_shape), end=\"\\r\")\n",
    "        try:\n",
    "            total_sum += s.run(next_element)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    return total_sum / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим $\\beta$, максимизируя выражение:\n",
    "$$L(A|s, \\beta) = -\\beta H(s) - M \\log\\sum_{i, j}\\exp -\\frac{\\beta}{2}(s_i - s_j - 1)^2$$\n",
    "\n",
    "Производные:\n",
    "$$L'_{\\beta}(A|s, \\beta) \n",
    "= - H(s) + \\frac{M}{2} \\frac{1}{\\sum_{i, j}e^{-\\frac{\\beta}{2}(s_i - s_j - 1)^2}}\\sum_{i, j}e^{-\\frac{\\beta}{2}(s_i - s_j - 1)^2} (s_i - s_j - 1)^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy(dataset, ranks):\n",
    "    dataset[\"from_rank\"] = ranks[\"rank\"].loc[[a for a, _ in dataset.index]].tolist()\n",
    "    dataset[\"to_rank\"] = ranks[\"rank\"].loc[[b for _, b in dataset.index]].tolist()\n",
    "    dataset[\"energy\"] = (dataset[\"from_rank\"] - dataset[\"to_rank\"] - 1) ** 2\n",
    "    return (dataset[\"value\"] * dataset[\"energy\"]).sum() / 2\n",
    "\n",
    "def infer_temperature(dataset, ranks):\n",
    "    H = calculate_energy(dataset, ranks)\n",
    "    M = float(dataset[\"value\"].sum())\n",
    "    beta_variable = tf.Variable(3.7268029290713383, name=\"beta\", dtype=tf.float64)\n",
    "    edges_sum_placeholder = tf.placeholder(tf.float64, shape=(None))\n",
    "    edges_sum_derivative_placeholder = tf.placeholder(tf.float64, shape=(None))\n",
    "    \n",
    "    derivative = - H + (M / 2) * (1 / edges_sum_placeholder) * edges_sum_derivative_placeholder\n",
    "    \n",
    "    @tf.custom_gradient\n",
    "    def loss_function(x):\n",
    "        loss = - H * x - M * edges_sum_placeholder\n",
    "        def grad(dy):\n",
    "            return dy * derivative\n",
    "        return loss, grad\n",
    "    \n",
    "    loss = loss_function(beta_variable)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "    \n",
    "    s.run(tf.global_variables_initializer())\n",
    "    for i in tqdm_notebook(range(0, 100)):\n",
    "        try:\n",
    "            beta = s.run(beta_variable)\n",
    "            edges_sum = predict_edges_sum(dataset, ranks, beta=beta, c=1)\n",
    "            edges_sum_derivative = calculate_edges_sum_derivative(dataset, ranks, beta=beta, c=1)\n",
    "            variables = {\n",
    "                edges_sum_placeholder: edges_sum, \n",
    "                edges_sum_derivative_placeholder: edges_sum_derivative\n",
    "            }\n",
    "            s.run(optimizer, variables)\n",
    "            print(\"Loss:\", s.run(loss, variables))\n",
    "            print(\"Derivative:\", s.run(derivative, variables))\n",
    "            print(\"Beta:\", s.run(beta_variable))\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "    return s.run(beta_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81c1da243bd4d47baf87dc9623b407b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -70731315738849.66\n",
      "Derivative: -1078.14000691189\n",
      "Beta: 111.54080522681414\n",
      "Loss: -13000444103182.412\n",
      "Derivative: -48423.36980997924\n",
      "Beta: 4953.877858381182\n",
      "Loss: -1950121905416.2412\n",
      "Derivative: -50087.110645871755\n",
      "Beta: 9962.588997603969\n",
      "Loss: -1375405751908.768\n",
      "Derivative: -50106.37025498278\n",
      "Beta: 14973.226097766557\n",
      "Loss: -1122247662290.8293\n",
      "Derivative: -50112.7450050751\n",
      "Beta: 19984.500672947877\n",
      "Loss: -971768504484.4802\n",
      "Derivative: -50115.92391616119\n",
      "Beta: 24996.09313924254\n",
      "Loss: -869291060218.2705\n",
      "Derivative: -50117.82865673278\n",
      "Beta: 30007.876079597205\n",
      "Loss: -793780565567.094\n",
      "Derivative: -50119.097368442686\n",
      "Beta: 35019.785891124746\n",
      "Loss: -735190527242.3546\n",
      "Derivative: -50120.00297606016\n",
      "Beta: 40031.786263415386\n",
      "Loss: -688036875659.7687\n",
      "Derivative: -50120.68178145469\n",
      "Beta: 45043.85451624649\n",
      "Loss: -649038910730.1238\n",
      "Derivative: -50121.20945551028\n",
      "Beta: 50055.97553648394\n",
      "Loss: -616098006893.3491\n",
      "Derivative: -50121.63138097233\n",
      "Beta: 55068.13874926822\n",
      "Loss: -587801037721.8431\n",
      "Derivative: -50121.976428848364\n",
      "Beta: 60080.33646684062\n",
      "Loss: -563157045510.5579\n",
      "Derivative: -50122.26384157779\n",
      "Beta: 65092.56292568639\n",
      "Loss: -541447838530.1029\n",
      "Derivative: -50122.5069376378\n",
      "Beta: 70104.81369413853\n",
      "Loss: -522138502680.5009\n",
      "Derivative: -50122.715227844696\n",
      "Beta: 75117.08529161167\n",
      "Loss: -504821358195.33234\n",
      "Derivative: -50122.895684906645\n",
      "Beta: 80129.37493479127\n",
      "Loss: -489179528057.0273\n",
      "Derivative: -50123.05353680793\n",
      "Beta: 85141.68036316123\n",
      "Loss: -474962492432.9116\n",
      "Derivative: -50123.19278014032\n",
      "Beta: 90153.99971586464\n",
      "Loss: -461969231872.3173\n",
      "Derivative: -50123.31652230675\n",
      "Beta: 95166.33144278488\n",
      "Loss: -450036324018.27606\n",
      "Derivative: -50123.42721564859\n",
      "Beta: 100178.67423903946\n",
      "Loss: -439029360934.2748\n",
      "Derivative: -50123.526821323874\n",
      "Beta: 105191.02699586173\n",
      "Loss: -428836645239.86816\n",
      "Derivative: -50123.61692635253\n",
      "Beta: 110203.38876318699\n",
      "Loss: -419364483003.1669\n",
      "Derivative: -50123.698828729954\n",
      "Beta: 115215.75872075012\n",
      "Loss: -410533616496.66754\n",
      "Derivative: -50123.77360032736\n",
      "Beta: 120228.1361554731\n",
      "Loss: -402276484395.8206\n",
      "Derivative: -50123.84213405835\n",
      "Beta: 125240.52044356927\n",
      "Loss: -394535091795.46735\n",
      "Derivative: -50123.90517971779\n",
      "Beta: 130252.9110362315\n",
      "Loss: -387259335886.5538\n",
      "Derivative: -50123.963371543505\n",
      "Beta: 135265.30744807638\n",
      "Loss: -380405676412.5283\n",
      "Derivative: -50124.01724964749\n",
      "Beta: 140277.70924773172\n",
      "Loss: -373936070030.8743\n",
      "Derivative: -50124.06727685\n",
      "Beta: 145290.1160501074\n",
      "Loss: -367817108829.87854\n",
      "Derivative: -50124.11385202674\n",
      "Beta: 150302.52751000083\n",
      "Loss: -362019318333.0249\n",
      "Derivative: -50124.15732078341\n",
      "Beta: 155314.94331677\n",
      "Loss: -356516581231.8686\n",
      "Derivative: -50124.19798406148\n",
      "Beta: 160327.363189867\n",
      "Loss: -351285661073.0036\n",
      "Derivative: -50124.23610512828\n",
      "Beta: 165339.78687507077\n",
      "Loss: -346305806034.80145\n",
      "Derivative: -50124.27191529429\n",
      "Beta: 170352.2141412912\n",
      "Loss: -341558417349.3903\n",
      "Derivative: -50124.30561862012\n",
      "Beta: 175364.64477784422\n",
      "Loss: -337026770262.90063\n",
      "Derivative: -50124.33739581538\n",
      "Beta: 180377.07859211686\n",
      "Loss: -332695777970.0356\n",
      "Derivative: -50124.36740748676\n",
      "Beta: 185389.51540755667\n",
      "Loss: -328551790913.1808\n",
      "Derivative: -50124.39579685865\n",
      "Beta: 190401.9550619337\n",
      "Loss: -324582425349.9769\n",
      "Derivative: -50124.422692063505\n",
      "Beta: 195414.39740583126\n",
      "Loss: -320776416274.5016\n",
      "Derivative: -50124.448208079375\n",
      "Beta: 200426.84230133044\n",
      "Loss: -317123490705.5888\n",
      "Derivative: -50124.47244837638\n",
      "Beta: 205439.28962085937\n",
      "Loss: -313614258090.3553\n",
      "Derivative: -50124.495506321844\n",
      "Beta: 210451.73924618287\n",
      "Loss: -310240115155.7613\n",
      "Derivative: -50124.51746638447\n",
      "Beta: 215464.19106751267\n",
      "Loss: -306993163009.468\n",
      "Derivative: -50124.53840517023\n",
      "Beta: 220476.64498272107\n",
      "Loss: -303866134668.5641\n",
      "Derivative: -50124.55839231683\n",
      "Beta: 225489.10089664417\n",
      "Loss: -300852331500.2715\n",
      "Derivative: -50124.577491268734\n",
      "Beta: 230501.5587204625\n",
      "Loss: -297945567307.47705\n",
      "Derivative: -50124.59575995097\n",
      "Beta: 235514.01837114905\n",
      "Loss: -295140118995.45264\n",
      "Derivative: -50124.613251356845\n",
      "Beta: 240526.47977097624\n",
      "Loss: -292430682923.24713\n",
      "Derivative: -50124.63001406207\n",
      "Beta: 245538.94284707395\n",
      "Loss: -289812336181.36163\n",
      "Derivative: -50124.64609267592\n",
      "Beta: 250551.4075310331\n",
      "Loss: -287280502151.6613\n",
      "Derivative: -50124.66152823807\n",
      "Beta: 255563.87375854846\n",
      "Loss: -284830919800.79956\n",
      "Derivative: -50124.6763585689\n",
      "Beta: 260576.34146909695\n",
      "Loss: -282459616237.9318\n",
      "Derivative: -50124.690618579094\n",
      "Beta: 265588.81060564646\n",
      "Loss: -280162882134.34204\n",
      "Derivative: -50124.70434054439\n",
      "Beta: 270601.2811143925\n",
      "Loss: -277937249658.7042\n",
      "Derivative: -50124.71755434962\n",
      "Beta: 275613.7529445191\n",
      "Loss: -275779472629.2284\n",
      "Derivative: -50124.73028770616\n",
      "Beta: 280626.2260479814\n",
      "2 of 3\r"
     ]
    }
   ],
   "source": [
    "infer_temperature(train, ranks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находим $c$, получая общее количество дуг (исходя из известного $\\beta$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_density(dataset, ranks, beta):\n",
    "    edges_sum = predict_edges_sum(dataset, ranks, beta, 1)\n",
    "    return dataset[\"value\"].sum() / edges_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_edges(dataset, ranks, beta, c):\n",
    "    dataset[\"from_rank\"] = ranks.loc[[a for a, _ in dataset.index]][\"rank\"].tolist()\n",
    "    dataset[\"to_rank\"] = ranks.loc[[b for _, b in dataset.index]][\"rank\"].tolist()\n",
    "    dataset[\"direction_probability\"] = (1 / (1 + np.exp(-2 * beta * (dataset[\"from_rank\"] - dataset[\"to_rank\"]))))\n",
    "    dataset[\"number_of_edges\"] = c * np.exp(- beta / 2 * (dataset[\"from_rank\"] - dataset[\"to_rank\"] - 1) ** 2)\n",
    "    return dataset[\"direction_probability\"].tolist(), dataset[\"number_of_edges\"].tolist(), predict_edges_sum(dataset, ranks, beta, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multigraph accuracy:\n",
    "$$\\sigma_a = 1 - \\frac{1}{2M}\\sum_{i,j}|{A_{ij} - (A_{ij} + A_{ji})P_{ij}}|$$\n",
    "\n",
    "M - сумма всех весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как пропустить ошибку для отсутствующих дуг?\n",
    "- Если Aij = 0 и Aji = 0 - ошибку можно пропустить?\n",
    "- Если Aij = 0 и Aji != 0\n",
    "$$A^*_{ij} = A_{ij}$$\n",
    "$$e_{ij} = |0 - A_{ji}(1 - P_{ji})| = A_{ji}(1 - P_{ij})$$\n",
    "$$e_{ij} + e_{ji} = |A_{ji} - A_{ji}P_{ji}| + A_{ji} - A_{ji}P_{ij} = 2(A_{ji} - A_{ji}P_{ij}) $$\n",
    "Т.е. для непарных дуг удваиваем ошибку\n",
    "\n",
    "Предполагается, что:\n",
    "$$A_{ij} = 0, A_{ji} = 0 \\rightarrow P_{ij} = 0, P_{ji} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ли возможность проверять предсказанное количество дуг?\n",
    "\n",
    "Есть, если вместо Aij + Aji использовать\n",
    "$$E_{ij} = c \\exp{-\\frac{\\beta}{2}(s_i - s_j - 1)^2}$$\n",
    "\n",
    "А вместо 2M?\n",
    "$$ M + \\sum_{ij}E_{ij} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для случая $A_{ji} = 0, A_{ij} \\neq 0$:\n",
    "\n",
    "$$E_{ji}(1 - P_{ji}) + |A_{ji} - E_{ji}P_{ji}|$$\n",
    "\n",
    "Для случая $A_{ij} = A_{ji} = 0$\n",
    "\n",
    "$$E_{ij}$$\n",
    "\n",
    "Т.е. сумма таких ошибок:\n",
    "\n",
    "$$\\sum E_{ij} - \\frac{\\sum_{(i,j), (j,i) \\in G} E_{ij}}{2} - \\sum_{(i,j) \\in G, (j, i) \\in G} E_{ij}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def accuracy(dataset, predictions):\n",
    "#     accuracy_dataset = dataset.copy()\n",
    "#     accuracy_dataset = accuracy_dataset.merge(accuracy_dataset.reset_index(), left_index=True, right_on=[\"to\", \"from\"], how=\"left\", suffixes=('', '_reversed'))\n",
    "#     accuracy_dataset[\"prediction\"] = predictions\n",
    "#     accuracy_dataset[\"total_value\"] = accuracy_dataset[\"value\"] + accuracy_dataset[\"value_reversed\"].fillna(0)\n",
    "#     accuracy_dataset[\"paired\"] = accuracy_dataset[\"value\"] < accuracy_dataset[\"total_value\"]\n",
    "#     accuracy_dataset[\"error\"] = accuracy_dataset[\"value\"] - accuracy_dataset[\"total_value\"] * accuracy_dataset[\"prediction\"]\n",
    "#     accuracy_dataset.loc[~accuracy_dataset[\"paired\"], \"error\"] *= 2\n",
    "#     return 1 - np.abs(accuracy_dataset[\"error\"]).sum() / 2 / accuracy_dataset[\"value\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(dataset, direction, edges, edges_sum):\n",
    "    accuracy_dataset = dataset.copy()\n",
    "    accuracy_dataset = accuracy_dataset.merge(accuracy_dataset.reset_index(), left_index=True, right_on=[\"to\", \"from\"], how=\"left\", suffixes=('', '_reversed'))\n",
    "    accuracy_dataset[\"not_paired\"] = 0\n",
    "    accuracy_dataset.loc[np.isnan(accuracy_dataset[\"value_reversed\"]), \"not_paired\"] = 1\n",
    "    accuracy_dataset[\"direction\"] = direction\n",
    "    accuracy_dataset[\"edges\"] = edges\n",
    "    accuracy_dataset[\"prediction\"] = accuracy_dataset[\"direction\"] * accuracy_dataset[\"edges\"]\n",
    "    accuracy_dataset[\"error\"] = np.abs(accuracy_dataset[\"value\"] - accuracy_dataset[\"prediction\"])\n",
    "    accuracy_dataset[\"non_paired_error\"] = accuracy_dataset[\"not_paired\"] * accuracy_dataset[\"edges\"] * (1 - accuracy_dataset[\"direction\"])\n",
    "    non_active_edges_sum = edges_sum - (accuracy_dataset[\"not_paired\"] * accuracy_dataset[\"edges\"]).sum() - ((1 - accuracy_dataset[\"not_paired\"]) * accuracy_dataset[\"edges\"]).sum() / 2\n",
    "    return 1 - \\\n",
    "        (accuracy_dataset[\"error\"].sum() + accuracy_dataset[\"non_paired_error\"].sum() + non_active_edges_sum) / \\\n",
    "        (accuracy_dataset[\"value\"].sum() + edges_sum) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test_df[\"from\"] = [\"0x1\", \"0x2\", \"0x3\"]\n",
    "test_df[\"to\"] = [\"0x2\", \"0x1\", \"0x4\"]\n",
    "test_df[\"value\"] = [1, 2, 1]\n",
    "test_df = test_df.set_index([\"from\", \"to\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 379420 samples\n",
      "Test size: 41996 samples\n",
      "Graph contains 379420 edges for 34394 nodes\n",
      "Estimated size of A is 4.7 MB RAM\n",
      "Matrix A takes 4.7 MB RAM\n",
      "Matrix has 3.21e-04 density\n",
      "03:06:32.886790 Calculating Anj ....\n",
      "03:06:33.271944 Calculating Ajn ....\n",
      "03:06:33.639343 Calculating A_o ....\n",
      "03:06:33.695075 Calculating B ....\n",
      "03:06:33.717737 Matrix B takes 19.1 MB RAM\n",
      "03:06:33.717828 Calculating b ....\n",
      "03:06:33.721348 Solving Bx=b equation using 'bicgstab' iterative method\n",
      "5 of 3\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: overflow encountered in exp\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362.3123372090965 379420.00000000244\n",
      "379420.00000000244 194921.88260753328\n",
      "Train accuracy:  0.0021349872317214524\n",
      "Test accuracy:  0.0006300630580420297\n",
      "{(0, 4922.40704411323, 0.07360470882683107): [0.0021349872317214524]}\n",
      "{(0, 4922.40704411323, 0.07360470882683107): [0.0006300630580420297]}\n"
     ]
    }
   ],
   "source": [
    "alphas = [0]\n",
    "# alphas = np.logspace(-2, 2, 5)\n",
    "betas = [4922.40704411323]\n",
    "# betas = [288808]\n",
    "split = ShuffleSplit(n_splits=5)\n",
    "# split = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "train_metrics = {}\n",
    "test_metrics = {}\n",
    "\n",
    "train_index, test_index = next(split.split(transactions_df))\n",
    "# for train_index, test_index in :\n",
    "train = create_dataset(transactions_df.loc[train_index])\n",
    "print(\"Train size: {} samples\".format(train.shape[0]))\n",
    "train_addresses = list([a for a, _ in train.index] + [b for _, b in train.index])\n",
    "test = create_dataset(transactions_df.loc[test_index], addresses=train_addresses)\n",
    "print(\"Test size: {} samples\".format(test.shape[0]))\n",
    "for alpha in alphas:\n",
    "    ranks = find_ranks(train, alpha=alpha)\n",
    "    for beta in betas:\n",
    "        c = infer_density(train, ranks, beta=beta)\n",
    "        train_directions, train_edges, train_sum = predict_edges(train, ranks, beta=beta, c=c)\n",
    "        print(beta * c, train_sum)\n",
    "        test_directions, test_edges, test_sum = predict_edges(test, ranks, beta=beta, c=c)\n",
    "        print(train_sum, test_sum)\n",
    "        train_metrics[(alpha, beta, c)] = train_metrics.get((alpha, beta, c), []) + [accuracy(train, train_directions, train_edges, train_sum)]\n",
    "        test_metrics[(alpha, beta, c)] = test_metrics.get((alpha, beta, c), []) + [accuracy(test, test_directions, test_edges, test_sum)]\n",
    "        print(\"Train accuracy: \", train_metrics[(alpha, beta, c)][-1])\n",
    "        print(\"Test accuracy: \", test_metrics[(alpha, beta, c)][-1])\n",
    "pprint(train_metrics)\n",
    "pprint(test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics_df = pd.DataFrame().from_dict(train_metrics).mean().to_frame().reset_index().rename(columns={\"level_0\": \"alpha\", \"level_1\": \"beta\", 0: \"accuracy\", \"level_2\": \"c\"})\n",
    "test_metrics_df = pd.DataFrame().from_dict(test_metrics).mean().to_frame().reset_index().rename(columns={\"level_0\": \"alpha\", \"level_1\": \"beta\", 0: \"accuracy\", \"level_2\": \"c\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in log\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_metrics_df[\"alpha_log\"] = np.log(test_metrics_df[\"alpha\"])\n",
    "train_metrics_df[\"alpha_log\"] = np.log(train_metrics_df[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1e356744e0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e35674a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_metrics_df.groupby(\"alpha_log\")[\"accuracy\"].mean(), label=\"train\")\n",
    "plt.plot(test_metrics_df.groupby(\"alpha_log\")[\"accuracy\"].mean(), label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>c</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>alpha_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.012454</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>0.021688</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>0.025061</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.028031</td>\n",
       "      <td>0.000766</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>0.030715</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>0.033184</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>0.035480</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.037637</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.039677</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha    beta         c  accuracy  alpha_log\n",
       "0      0   100.0  0.012454  0.000755       -inf\n",
       "1      0   200.0  0.017683  0.000762       -inf\n",
       "2      0   300.0  0.021688  0.000764       -inf\n",
       "3      0   400.0  0.025061  0.000766       -inf\n",
       "4      0   500.0  0.028031  0.000766       -inf\n",
       "5      0   600.0  0.030715  0.000767       -inf\n",
       "6      0   700.0  0.033184  0.000767       -inf\n",
       "7      0   800.0  0.035480  0.000767       -inf\n",
       "8      0   900.0  0.037637  0.000767       -inf\n",
       "9      0  1000.0  0.039677  0.000767       -inf"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_metrics_df.sort_values(\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1db71d2630>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e1af0f668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_metrics_df.groupby(\"beta\")[\"accuracy\"].max(), label=\"train\")\n",
    "plt.plot(test_metrics_df.groupby(\"beta\")[\"accuracy\"].max(), label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1e26678be0>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1e3567eeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_metrics_df.groupby(\"c\")[\"accuracy\"].max(), label=\"train\")\n",
    "plt.plot(test_metrics_df.groupby(\"c\")[\"accuracy\"].max(), label=\"test\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airdrops search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Считаем спрингранк для графа токенов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
